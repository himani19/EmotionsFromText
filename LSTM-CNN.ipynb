{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/priya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'fear' 'anger' 'sadness' 'disgust' 'shame' 'guilt']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Data/phrases.csv\")\n",
    "# data=pd.DataFrame(data)\n",
    "# print type(data)\n",
    "print data['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel closing to my partner and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                             Phrase\n",
       "0      joy  On days when I feel closing to my partner and ...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data\n",
    "def clean_dataset(data):\n",
    "    translator = string.maketrans('', '')\n",
    "    for index,row in data.iterrows():\n",
    "        row['Phrase'] = row['Phrase'].replace('[','')\n",
    "        row['Phrase'] = row['Phrase'].replace(']','')\n",
    "        row['Phrase'] = row['Phrase'].strip()\n",
    "        row['Phrase'] = row['Phrase'].translate(translator,string.punctuation)\n",
    "    return data\n",
    "data = clean_dataset(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>days feel closing partner friends when feel pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>every time imagine someone love could contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>obviously unjustly treated possibility of eluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>think short time live relate the periods life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>gathering found involuntarily sitting next two...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                             Phrase\n",
       "0      joy  days feel closing partner friends when feel pe...\n",
       "1     fear  every time imagine someone love could contact ...\n",
       "2    anger  obviously unjustly treated possibility of eluc...\n",
       "3  sadness  think short time live relate the periods life ...\n",
       "4  disgust  gathering found involuntarily sitting next two..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenise(data):\n",
    "    ## Convert words to lower case and split them    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for index,row in data.iterrows():\n",
    "        text = row['Phrase'].lower().split(' ')\n",
    "        text = [w.strip() for w in text if not w in stops and len(w) >= 2]\n",
    "        text = \" \".join(text)\n",
    "        row['Phrase'] = text\n",
    "    # split the dataset into tokens\n",
    "    return data\n",
    "data = tokenise(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>list_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>day feel close partner friend when feel peac a...</td>\n",
       "      <td>[day, feel, close, partner, friend, when, feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>everi time imagin someon love could contact se...</td>\n",
       "      <td>[everi, time, imagin, someon, love, could, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>obvious unjust treat possibl of elucid</td>\n",
       "      <td>[obvious, unjust, treat, possibl, of, elucid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>think short time live relat the period life th...</td>\n",
       "      <td>[think, short, time, live, relat, the, period,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>gather found involuntarili sit next two peopl ...</td>\n",
       "      <td>[gather, found, involuntarili, sit, next, two,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                             Phrase  \\\n",
       "0      joy  day feel close partner friend when feel peac a...   \n",
       "1     fear  everi time imagin someon love could contact se...   \n",
       "2    anger             obvious unjust treat possibl of elucid   \n",
       "3  sadness  think short time live relat the period life th...   \n",
       "4  disgust  gather found involuntarili sit next two peopl ...   \n",
       "\n",
       "                                       list_of_words  \n",
       "0  [day, feel, close, partner, friend, when, feel...  \n",
       "1  [everi, time, imagin, someon, love, could, con...  \n",
       "2      [obvious, unjust, treat, possibl, of, elucid]  \n",
       "3  [think, short, time, live, relat, the, period,...  \n",
       "4  [gather, found, involuntarili, sit, next, two,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(dataset):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    list_of_words=[]\n",
    "    for index,row in dataset.iterrows():\n",
    "        text = row['Phrase'].split()\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        list_of_words.append(stemmed_words)\n",
    "        text = \" \".join(stemmed_words)\n",
    "        row['Phrase'] = text\n",
    "    data['list_of_words'] = list_of_words\n",
    "    return dataset\n",
    "data = lemmatization(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Reshape\n",
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(data['Phrase'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(data['Phrase'])\n",
    "tokenized_data = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = data['Emotion'].unique()\n",
    "# print X\n",
    "X=X.reshape(-1,1)\n",
    "# print X\n",
    "enc.fit(X)\n",
    "enc.categories_\n",
    "emotion_data=data['Emotion'].values\n",
    "emotion_data=emotion_data.reshape(-1,1)\n",
    "emotion_data=enc.transform(emotion_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phrase, validate_phrase = np.split(tokenized_data,[int(.8*len(tokenized_data))])\n",
    "train_label,validate_emotion=np.split(emotion_data,[int(.8*len(emotion_data))])\n",
    "# train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(None, 50)\n",
      "(None, 50, 35)\n",
      "(None, 50)\n",
      "(None, 47, 40)\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "6121/6121 [==============================] - 41s 7ms/step - loss: 0.1221 - acc: 0.1573\n",
      "Epoch 2/5\n",
      "6121/6121 [==============================] - 35s 6ms/step - loss: 0.1127 - acc: 0.2808\n",
      "Epoch 3/5\n",
      "6121/6121 [==============================] - 34s 6ms/step - loss: 0.1006 - acc: 0.3811\n",
      "Epoch 4/5\n",
      "6121/6121 [==============================] - 35s 6ms/step - loss: 0.0858 - acc: 0.5066\n",
      "Epoch 5/5\n",
      "6112/6121 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.6284"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 100, input_length=50))\n",
    "model.add(LSTM(70, dropout=0.2, return_sequences=True, recurrent_dropout=0.2))\n",
    "model.add(LSTM(35, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "print model.input_shape\n",
    "print model.output_shape\n",
    "# model.add(Reshape([50,-1]))\n",
    "model.add(Conv1D (kernel_size = (4), filters = 40, activation='relu'))\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)\n",
    "# model.add(Flatten())\n",
    "model.add(MaxPooling1D(pool_size = (4), strides=(1)))\n",
    "# print(model.output_shape)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_phrase, np.array(train_label), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_emo=model.predict(validate_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=(enc.inverse_transform(predicted_emo)).reshape(-1)\n",
    "actual = (enc.inverse_transform(validate_emotion)).reshape(-1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(actual,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(text):\n",
    "#     cleaning\n",
    "    translator = string.maketrans('', '')\n",
    "    text = text.replace('[','')\n",
    "    text = text.replace(']','')\n",
    "    text = text.strip()\n",
    "    text = text.translate(translator,string.punctuation)\n",
    "#     stop word removal\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = text.lower().split(' ')\n",
    "    text = [w.strip() for w in text if not w in stops and len(w) >= 2]\n",
    "    text = \" \".join(text)\n",
    "#     lemmatization\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    text = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences([data_preprocess('I am ashamed!')])\n",
    "test_data = pad_sequences(sequences, maxlen=50)\n",
    "pred_emo = model.predict(test_data)\n",
    "test_op = (enc.inverse_transform(pred_emo)).reshape(-1)\n",
    "test_op"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
