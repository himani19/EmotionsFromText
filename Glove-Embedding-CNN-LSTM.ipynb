{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/priya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense,LSTM, Input, GlobalMaxPooling1D,Flatten,Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'fear' 'anger' 'sadness' 'disgust' 'shame' 'guilt']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Data/phrases.csv\")\n",
    "# data=pd.DataFrame(data)\n",
    "data = data.dropna()\n",
    "print(data['Emotion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel closing to my partner and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                             Phrase\n",
       "0      joy  On days when I feel closing to my partner and ...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_dataset(data):\n",
    "    translator = string.maketrans('', '')\n",
    "    for index,row in data.iterrows():\n",
    "        row['Phrase'] = row['Phrase'].replace('[','')\n",
    "        row['Phrase'] = row['Phrase'].replace(']','')\n",
    "        row['Phrase'] = row['Phrase'].strip()\n",
    "        row['Phrase'] = row['Phrase'].translate(translator,string.punctuation)\n",
    "    return data\n",
    "data = clean_dataset(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>days feel closing partner friends when feel pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>every time imagine someone love could contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>obviously unjustly treated possibility of eluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>think short time live relate the periods life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>gathering found involuntarily sitting next two...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                             Phrase\n",
       "0      joy  days feel closing partner friends when feel pe...\n",
       "1     fear  every time imagine someone love could contact ...\n",
       "2    anger  obviously unjustly treated possibility of eluc...\n",
       "3  sadness  think short time live relate the periods life ...\n",
       "4  disgust  gathering found involuntarily sitting next two..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenise(data):\n",
    "    ## Convert words to lower case and split them    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for index,row in data.iterrows():\n",
    "        text = row['Phrase'].lower().split(' ')\n",
    "        text = [w.strip() for w in text if not w in stops and len(w) >= 2]\n",
    "        text = \" \".join(text)\n",
    "        row['Phrase'] = text\n",
    "    # split the dataset into tokens\n",
    "    return data\n",
    "data = tokenise(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>list_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>day feel close partner friend when feel peac a...</td>\n",
       "      <td>[day, feel, close, partner, friend, when, feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>everi time imagin someon love could contact se...</td>\n",
       "      <td>[everi, time, imagin, someon, love, could, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>obvious unjust treat possibl of elucid</td>\n",
       "      <td>[obvious, unjust, treat, possibl, of, elucid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>think short time live relat the period life th...</td>\n",
       "      <td>[think, short, time, live, relat, the, period,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>gather found involuntarili sit next two peopl ...</td>\n",
       "      <td>[gather, found, involuntarili, sit, next, two,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                             Phrase  \\\n",
       "0      joy  day feel close partner friend when feel peac a...   \n",
       "1     fear  everi time imagin someon love could contact se...   \n",
       "2    anger             obvious unjust treat possibl of elucid   \n",
       "3  sadness  think short time live relat the period life th...   \n",
       "4  disgust  gather found involuntarili sit next two peopl ...   \n",
       "\n",
       "                                       list_of_words  \n",
       "0  [day, feel, close, partner, friend, when, feel...  \n",
       "1  [everi, time, imagin, someon, love, could, con...  \n",
       "2      [obvious, unjust, treat, possibl, of, elucid]  \n",
       "3  [think, short, time, live, relat, the, period,...  \n",
       "4  [gather, found, involuntarili, sit, next, two,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(dataset):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    list_of_words=[]\n",
    "    for index,row in dataset.iterrows():\n",
    "        text = row['Phrase'].split()\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        list_of_words.append(stemmed_words)\n",
    "        text = \" \".join(stemmed_words)\n",
    "        row['Phrase'] = text\n",
    "    data['list_of_words'] = list_of_words\n",
    "    return dataset\n",
    "data = lemmatization(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(text):\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['Phrase'])\n",
    "\n",
    "token_tr_X = tokenizer.texts_to_sequences(data['Phrase'])\n",
    "x_train_text = []\n",
    "\n",
    "x_train_text = pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "#     return x_train_text,tokenizer\n",
    "# x_train_text,tokenizer = tokenize(data['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6538 unique tokens\n",
      "./glove.6B/glove.6B.300d.txt\n",
      "G Word embeddings: 400000\n",
      "G Null word embeddings: 2388\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "file_loc = './glove.6B/glove.6B.300d.txt'\n",
    "\n",
    "print (file_loc)\n",
    "\n",
    "gembeddings_index = {}\n",
    "with codecs.open(file_loc, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "#\n",
    "f.close()\n",
    "print('G Word embeddings:', len(gembeddings_index))\n",
    "\n",
    "nb_words = len(word_index) +1\n",
    "g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    gembedding_vector = gembeddings_index.get(word)\n",
    "    if gembedding_vector is not None:\n",
    "        g_word_embedding_matrix[i] = gembedding_vector\n",
    "        \n",
    "print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "Y=(data['Emotion']).tolist()\n",
    "Y = lb.fit_transform(Y)\n",
    "\n",
    "# for ses_mod in data:\n",
    "#     Y.append(ses_mod['Emotion'])\n",
    "    \n",
    "# Y = label_binarize(Y,(data['Emotion'].unique()).tolist())\n",
    "\n",
    "Y.shape\n",
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
